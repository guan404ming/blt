{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-LEHyoib9Ps",
        "outputId": "085e301d-2902-43b7-a069-341b2c2bf257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= Cell 1: ç’°å¢ƒå®‰è£ (é»ƒé‡‘ç©©å®šç‰ˆ) =================\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"â³ [1/4] æ­£åœ¨ç§»é™¤è¡çªå¥—ä»¶...\")\n",
        "# å…ˆç§»é™¤å¯èƒ½å­˜åœ¨çš„è¡çªç‰ˆæœ¬\n",
        "!pip uninstall -y torchaudio torchcodec librosa numpy\n",
        "\n",
        "print(\"â³ [2/4] å®‰è£ç³»çµ±ä¾è³´ (FFmpeg & Fonts)...\")\n",
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install -y ffmpeg fonts-noto-cjk\n",
        "\n",
        "print(\"â³ [3/4] å®‰è£ Python å¥—ä»¶ (é–å®šç©©å®šç‰ˆæœ¬)...\")\n",
        "# é—œéµä¿®æ­£ï¼š\n",
        "# 1. torchaudio==2.4.1: é¿é–‹ 2.5+ ç‰ˆçš„ TorchCodec éŒ¯èª¤\n",
        "# 2. librosa==0.9.2: ç¢ºä¿ Wav2Lip èƒ½è·‘ (å®ƒä¸æ”¯æ´ librosa 0.10+)\n",
        "# 3. numpy<2.0: é¿å…æ–°ç‰ˆ Numpy çš„å…¼å®¹æ€§å•é¡Œ\n",
        "!pip install -q \"torch>=2.4.0\" \"torchaudio==2.4.1\" \"soundfile\" \"demucs\" \"stable-ts\" \"gradio_client\" \"pydub\" \"yt-dlp\" \"opencc-python-reimplemented\" \"librosa==0.9.2\" \"opencv-python\" \"numpy<2.0\"\n",
        "\n",
        "print(\"â³ [4/4] æº–å‚™ Wav2Lip æ¨¡å‹...\")\n",
        "# 1. Clone Wav2Lip\n",
        "if not os.path.exists('/content/Wav2Lip'):\n",
        "    !git clone https://github.com/Rudrabha/Wav2Lip.git\n",
        "\n",
        "# 2. ä¸‹è¼‰æ¨¡å‹\n",
        "!mkdir -p /content/Wav2Lip/checkpoints\n",
        "!mkdir -p /content/Wav2Lip/face_detection/detection/sfd\n",
        "\n",
        "if not os.path.exists('/content/Wav2Lip/checkpoints/wav2lip_gan.pth'):\n",
        "    print(\"   â¬‡ï¸ ä¸‹è¼‰ wav2lip_gan.pth...\")\n",
        "    !wget -q -c https://huggingface.co/camenduru/Wav2Lip/resolve/main/checkpoints/wav2lip_gan.pth -O /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
        "\n",
        "if not os.path.exists('/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth'):\n",
        "    print(\"   â¬‡ï¸ ä¸‹è¼‰ s3fd.pth...\")\n",
        "    !wget -q -c \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
        "\n",
        "# 3. å†æ¬¡æ‡‰ç”¨ Wav2Lip ä»£ç¢¼ä¿®è£œ (ç¢ºä¿è¬ç„¡ä¸€å¤±)\n",
        "def patch_code(file_path, old_str, new_str):\n",
        "    if not os.path.exists(file_path): return\n",
        "    with open(file_path, 'r') as f: content = f.read()\n",
        "    if old_str in content:\n",
        "        content = content.replace(old_str, new_str)\n",
        "        with open(file_path, 'w') as f: f.write(content)\n",
        "        print(f\"   ğŸ”§ å·²ä¿®è£œ: {os.path.basename(file_path)}\")\n",
        "\n",
        "w2l_path = \"/content/Wav2Lip\"\n",
        "patch_code(f\"{w2l_path}/audio.py\", \"librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=80)\", \"librosa.filters.mel(sr=hp.sample_rate, n_fft=hp.n_fft, n_mels=80)\")\n",
        "patch_code(f\"{w2l_path}/audio.py\", \"np.int\", \"int\")\n",
        "patch_code(f\"{w2l_path}/audio.py\", \"np.float\", \"float\")\n",
        "patch_code(f\"{w2l_path}/inference.py\", \"np.int\", \"int\")\n",
        "patch_code(f\"{w2l_path}/inference.py\", \"np.float\", \"float\")\n",
        "patch_code(f\"{w2l_path}/inference.py\", \"img = cv2.resize(window, (img_size, img_size))\", \"img = cv2.resize(window, (img_size, img_size), interpolation=cv2.INTER_LANCZOS4)\")\n",
        "\n",
        "print(\"â³ æ›è¼‰ Google Drive...\")\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\nâœ… ç’°å¢ƒå®‰è£å®Œæˆï¼\")\n",
        "print(\"âš ï¸ è«‹å‹™å¿…é»æ“Šä¸Šæ–¹é¸å–®çš„ [Runtime] -> [Restart Session]ï¼Œç„¶å¾Œå†åŸ·è¡Œ Cell 2 å’Œ Cell 3ï¼\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar_RRTZdEA8M",
        "outputId": "7caddb9e-b104-469f-8924-eb24d88f67ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ [1/4] æ­£åœ¨ç§»é™¤è¡çªå¥—ä»¶...\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "\u001b[33mWARNING: Skipping torchcodec as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: librosa 0.11.0\n",
            "Uninstalling librosa-0.11.0:\n",
            "  Successfully uninstalled librosa-0.11.0\n",
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "â³ [2/4] å®‰è£ç³»çµ±ä¾è³´ (FFmpeg & Fonts)...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "Suggested packages:\n",
            "  fonts-noto-cjk-extra\n",
            "The following NEW packages will be installed:\n",
            "  fonts-noto-cjk\n",
            "0 upgraded, 1 newly installed, 0 to remove and 48 not upgraded.\n",
            "Need to get 61.2 MB of archives.\n",
            "After this operation, 93.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-cjk all 1:20220127+repack1-1 [61.2 MB]\n",
            "Fetched 61.2 MB in 4s (16.3 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-noto-cjk.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-noto-cjk_1%3a20220127+repack1-1_all.deb ...\n",
            "Unpacking fonts-noto-cjk (1:20220127+repack1-1) ...\n",
            "Setting up fonts-noto-cjk (1:20220127+repack1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "â³ [3/4] å®‰è£ Python å¥—ä»¶ (é–å®šç©©å®šç‰ˆæœ¬)...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m189.1/189.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m797.0/797.0 MB\u001b[0m \u001b[31m820.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for stable-ts (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.4.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâ³ [4/4] æº–å‚™ Wav2Lip æ¨¡å‹...\n",
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 409, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 409 (delta 2), reused 0 (delta 0), pack-reused 405 (from 2)\u001b[K\n",
            "Receiving objects: 100% (409/409), 549.28 KiB | 13.40 MiB/s, done.\n",
            "Resolving deltas: 100% (227/227), done.\n",
            "   â¬‡ï¸ ä¸‹è¼‰ wav2lip_gan.pth...\n",
            "   â¬‡ï¸ ä¸‹è¼‰ s3fd.pth...\n",
            "   ğŸ”§ å·²ä¿®è£œ: audio.py\n",
            "â³ æ›è¼‰ Google Drive...\n",
            "\n",
            "âœ… ç’°å¢ƒå®‰è£å®Œæˆï¼\n",
            "âš ï¸ è«‹å‹™å¿…é»æ“Šä¸Šæ–¹é¸å–®çš„ [Runtime] -> [Restart Session]ï¼Œç„¶å¾Œå†åŸ·è¡Œ Cell 2 å’Œ Cell 3ï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= Cell 2: å·¥å…·å‡½æ•¸å®šç¾© =================\n",
        "\n",
        "import datetime\n",
        "import stable_whisper\n",
        "import os\n",
        "\n",
        "# ç¢ºä¿ OpenCC å­˜åœ¨\n",
        "try:\n",
        "    from opencc import OpenCC\n",
        "except ImportError:\n",
        "    os.system(\"pip install opencc-python-reimplemented\")\n",
        "    from opencc import OpenCC\n",
        "\n",
        "# æ™‚é–“æ ¼å¼åŒ–å·¥å…·\n",
        "def format_time(seconds):\n",
        "    dt = datetime.datetime.utcfromtimestamp(seconds)\n",
        "    return dt.strftime('%-H:%M:%S.%f')[:-4]\n",
        "\n",
        "# 1. é›™è»Œé‡çµ„é‚è¼¯\n",
        "def realign_dual_tracks(original_result, user_lyrics_str, user_soramimi_str):\n",
        "    print(\"   ğŸ§© æ­£åœ¨è¨ˆç®—é›™è»Œæ­Œè©å°é½Š...\")\n",
        "    all_words = []\n",
        "    for seg in original_result.segments:\n",
        "        all_words.extend(seg.words)\n",
        "\n",
        "    target_lines = [line.strip() for line in user_lyrics_str.strip().split('\\n') if line.strip()]\n",
        "    soramimi_lines = [line.strip() for line in user_soramimi_str.strip().split('\\n') if line.strip()]\n",
        "\n",
        "    min_len = min(len(target_lines), len(soramimi_lines))\n",
        "    new_segments = []\n",
        "    word_index = 0\n",
        "\n",
        "    for i in range(min_len):\n",
        "        line_text = target_lines[i]\n",
        "        sora_text = soramimi_lines[i]\n",
        "        current_segment_words = []\n",
        "        clean_line_len = len(line_text.replace(\" \", \"\"))\n",
        "        grabbed_chars = 0\n",
        "\n",
        "        while grabbed_chars < clean_line_len and word_index < len(all_words):\n",
        "            word_obj = all_words[word_index]\n",
        "            current_segment_words.append(word_obj)\n",
        "            grabbed_chars += len(word_obj.word.strip())\n",
        "            word_index += 1\n",
        "\n",
        "        if current_segment_words:\n",
        "            new_segments.append({\n",
        "                \"start\": current_segment_words[0].start,\n",
        "                \"end\": current_segment_words[-1].end,\n",
        "                \"words\": current_segment_words,\n",
        "                \"text_main\": line_text,\n",
        "                \"text_sub\": sora_text\n",
        "            })\n",
        "    return new_segments\n",
        "\n",
        "# 2. ç”Ÿæˆé›™è»Œ ASS å­—å¹•æª”\n",
        "def generate_ktv_ass_dual(segments, ass_path, font_name=\"Noto Sans CJK TC\"):\n",
        "    header = f\"\"\"[Script Info]\n",
        "ScriptType: v4.00+\n",
        "PlayResX: 1920\n",
        "PlayResY: 1080\n",
        "\n",
        "[V4+ Styles]\n",
        "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
        "Style: MainStyle,{font_name},60,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,0,2,10,10,65,1\n",
        "Style: SubStyle,{font_name},40,&H0000FFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,0,2,10,10,15,1\n",
        "\n",
        "[Events]\n",
        "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
        "\"\"\"\n",
        "    events = []\n",
        "    cc = OpenCC('s2t')\n",
        "\n",
        "    for seg in segments:\n",
        "        start_time = format_time(seg['start'])\n",
        "        end_time = format_time(seg['end'])\n",
        "\n",
        "        # --- åŸè© ---\n",
        "        k_text_main = \"\"\n",
        "        for i, word in enumerate(seg['words']):\n",
        "            duration = int((word.end - word.start) * 100)\n",
        "            raw_word = word.word\n",
        "            has_chinese = any('\\u4e00' <= char <= '\\u9fff' for char in raw_word)\n",
        "\n",
        "            if has_chinese:\n",
        "                word_text = cc.convert(raw_word.strip())\n",
        "            else:\n",
        "                clean_word = raw_word.strip()\n",
        "                if i == 0: word_text = clean_word\n",
        "                else: word_text = \" \" + clean_word\n",
        "\n",
        "            if word_text:\n",
        "                k_text_main += f\"{{\\\\k{duration}}}{word_text}\"\n",
        "\n",
        "        if k_text_main:\n",
        "            events.append(f\"Dialogue: 0,{start_time},{end_time},MainStyle,,0,0,0,,{{\\\\df2}}{k_text_main}\")\n",
        "\n",
        "        # --- ç©ºè€³ ---\n",
        "        sora_text = seg['text_sub']\n",
        "        if sora_text:\n",
        "            total_duration = int((seg['end'] - seg['start']) * 100)\n",
        "            events.append(f\"Dialogue: 0,{start_time},{end_time},SubStyle,,0,0,0,,{{\\\\df2}}{{\\\\k{total_duration}}}{sora_text}\")\n",
        "\n",
        "    with open(ass_path, \"w\", encoding='utf-8') as f:\n",
        "        f.write(header + \"\\n\".join(events))\n",
        "    print(f\"   âœ¨ é›™è»Œ ASS å­—å¹•æª”å·²ç”Ÿæˆ: {ass_path}\")\n",
        "\n",
        "print(\"âœ… å·¥å…·å‡½æ•¸åŠ è¼‰å®Œç•¢ï¼\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUF-NxFJEBn2",
        "outputId": "968d2bf7-e8ef-449f-c393-21226c772530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å·¥å…·å‡½æ•¸åŠ è¼‰å®Œç•¢ï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= Cell 3: åŸ·è¡Œç”Ÿæˆæµæ°´ç·š (åƒæ•¸é †åºä¿®æ­£ç‰ˆ) =================\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import torch\n",
        "import stable_whisper\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from gradio_client import Client, handle_file\n",
        "from pydub import AudioSegment\n",
        "from demucs.separate import main as demucs_main\n",
        "\n",
        "# å†æ¬¡ç¢ºèª Numpy è£œä¸\n",
        "import numpy as np\n",
        "if not hasattr(np, 'float'): np.float = float\n",
        "if not hasattr(np, 'int'): np.int = int\n",
        "\n",
        "# ================= 1. åƒæ•¸è¨­å®šå€ =================\n",
        "input_original_song = \"/content/drive/MyDrive/demo/demo.mp3\"\n",
        "input_user_cover    = \"/content/drive/MyDrive/demo/demo.mp3\"\n",
        "image_input_path    = \"/content/drive/MyDrive/demo/æ¡¶.jpg\"\n",
        "\n",
        "model_pth   = \"/content/drive/MyDrive/demo/model.pth\"\n",
        "model_index = \"/content/drive/MyDrive/demo/model.index\"\n",
        "f0_change   = 0\n",
        "\n",
        "lyrics_input = \"\"\"\n",
        "The snow glows white on the mountain tonight\n",
        "Not a footprint to be seen\n",
        "A kingdom of isolation\n",
        "and it looks like I'm the queen\n",
        "The wind is howling like this swirling storm inside\n",
        "Couldn't keep it in\n",
        "Heaven knows I've tried\n",
        "\"\"\"\n",
        "\n",
        "soramimi_input = \"\"\"\n",
        "ç‰¹æ–¯è«¾ å“¥ç¾…æ–¯ å¤–ç‰¹ å™¢æ© å¾· é¦¬æ©å»· æ‰˜å¥ˆç‰¹\n",
        "è«¾ è¯¶ é¦®ç‰¹æ™® å…¥ å” è² å®‹\n",
        "å•Š é‡‘å¾·å§† å“¦å¤« ä¾ç‘Ÿæ‹‰ç”³\n",
        "å®‰ ä¾ç‰¹ èŠ±æ ¼ èŠå…‹ çˆ±å§† å¾· å¥å› \n",
        "å¾· å¨æ© å¾· ç‘™æ— èŠå…‹ æ¯ æ–¯æ²ƒæ— æ–¯æ‰˜å§† å†…è¨å¾·\n",
        "æ‰£å¾— è‚¯ çˆ±ç‰¹ å› \n",
        "æµ·æ–‡ å¥ˆå…¹ çˆ±å¼— ç‰¹èµ–å¾·\n",
        "\"\"\"\n",
        "\n",
        "lyrics_language = 'en'\n",
        "output_dir = \"/content/drive/MyDrive/RVCè½‰æ›/Final_Ultimate_Output\"\n",
        "\n",
        "# ==========================================================\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "temp_dir = Path(\"/content/temp_dual_process\")\n",
        "if temp_dir.exists(): shutil.rmtree(temp_dir)\n",
        "temp_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "input_original_song = os.path.abspath(input_original_song)\n",
        "input_user_cover = os.path.abspath(input_user_cover)\n",
        "\n",
        "%cd /content/Wav2Lip\n",
        "song_name = Path(input_user_cover).stem\n",
        "print(f\"ğŸš€ çµ‚æ¥µæµæ°´ç·šå•Ÿå‹•ï¼ç›®æ¨™æ­Œæ›²ï¼š{song_name}\")\n",
        "\n",
        "\n",
        "# --- éšæ®µ 1: éŸ³æºåˆ†é›¢ (Demucs) ---\n",
        "print(\"\\n=== [1/5] éŸ³æºåˆ†é›¢è™•ç† ===\")\n",
        "def run_demucs_safe(input_file, output_path):\n",
        "    print(f\"   âœ‚ï¸ è™•ç†éŸ³è¨Š: {os.path.basename(input_file)}...\")\n",
        "    temp_wav = temp_dir / (Path(input_file).stem + \"_clean.wav\")\n",
        "    AudioSegment.from_file(input_file).export(temp_wav, format=\"wav\")\n",
        "    args = [\"-n\", \"htdemucs\", \"--two-stems=vocals\", \"-o\", str(output_path), str(temp_wav)]\n",
        "    try:\n",
        "        demucs_main(args)\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸ GPU æ¨¡å¼å¤±æ•—ï¼Œå˜—è©¦åˆ‡æ›è‡³ CPU...\")\n",
        "        args.extend([\"-d\", \"cpu\"])\n",
        "        demucs_main(args)\n",
        "\n",
        "try:\n",
        "    run_demucs_safe(input_original_song, temp_dir / \"bgm_source\")\n",
        "    bgm_stem = Path(input_original_song).stem + \"_clean\"\n",
        "    final_inst_path = temp_dir / \"bgm_source\" / \"htdemucs\" / bgm_stem / \"no_vocals.wav\"\n",
        "\n",
        "    run_demucs_safe(input_user_cover, temp_dir / \"vocal_source\")\n",
        "    vocal_stem = Path(input_user_cover).stem + \"_clean\"\n",
        "    user_vocals_path = temp_dir / \"vocal_source\" / \"htdemucs\" / vocal_stem / \"vocals.wav\"\n",
        "\n",
        "    if not final_inst_path.exists() or not user_vocals_path.exists():\n",
        "        raise FileNotFoundError(\"åˆ†é›¢æª”æ¡ˆæœªç”Ÿæˆ\")\n",
        "    print(\"      âœ… éŸ³æºåˆ†é›¢å®Œæˆ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Demucs éŒ¯èª¤: {e}\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "# --- éšæ®µ 2: AI è®Šè² (RVC) ---\n",
        "print(\"\\n=== [2/5] AI è®Šè²è½‰æ› (RVC API - é †åºä¿®æ­£ç‰ˆ) ===\")\n",
        "try:\n",
        "    client = Client(\"r3gm/RVC_ZERO\")\n",
        "\n",
        "    # å»ºç«‹ Handle\n",
        "    audio_handle = handle_file(str(user_vocals_path))\n",
        "    model_handle = handle_file(model_pth)\n",
        "    index_handle = handle_file(model_index)\n",
        "\n",
        "    print(\"   ğŸ“¡ ç™¼é€ API è«‹æ±‚...\")\n",
        "\n",
        "    # âš ï¸ã€é—œéµä¿®æ­£ã€‘ä¾ç…§éŒ¯èª¤è¨Šæ¯èª¿æ•´é †åº\n",
        "    # æ ¹æ“š Error: Parameter 3 expects Method (rmvpe+), not Index File.\n",
        "    # æ–°é †åºé æ¸¬: [Audio], Model, Method, Pitch, Index ...\n",
        "    result = client.predict(\n",
        "        [audio_handle],      # 1. éŸ³è¨Š (å¿…é ˆæ˜¯ List)\n",
        "        model_handle,        # 2. æ¨¡å‹ (.pth)\n",
        "        \"rmvpe+\",            # 3. æ¼”ç®—æ³• (åŸæœ¬éŒ¯æ”¾æˆ index, ç¾åœ¨ç§»åˆ°é€™è£¡)\n",
        "        f0_change,           # 4. è®Šèª¿ (int)\n",
        "        index_handle,        # 5. Index æª”æ¡ˆ (åŸæœ¬åœ¨ç¬¬3ä½, ç¾åœ¨ç§»åˆ°é€™è£¡)\n",
        "        0.75,                # 6. Index Rate\n",
        "        3,                   # 7. Filter Radius\n",
        "        0,                   # 8. Resample\n",
        "        0.25,                # 9. RMS Mix\n",
        "        0.33,                # 10. Protect\n",
        "        api_name=\"/run\"\n",
        "    )\n",
        "\n",
        "    # çµæœè™•ç†\n",
        "    converted_vocal_path = result[0] if isinstance(result, (list, tuple)) else result\n",
        "    print(f\"      âœ… è®Šè²æˆåŠŸ: {converted_vocal_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ RVC éŒ¯èª¤: {e}\")\n",
        "    print(\"ğŸ’¡ è‹¥é€™æ¬¡é‚„æ˜¯åƒæ•¸éŒ¯èª¤ï¼Œæˆ‘å€‘å°‡éœ€è¦åŸ·è¡Œã€ŒAPI è¨ºæ–·è…³æœ¬ã€ä¾†æŸ¥çœ‹æœ€æ­£ç¢ºçš„åƒæ•¸è¡¨ã€‚\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "# --- éšæ®µ 3: æ··éŸ³ ---\n",
        "print(\"\\n=== [3/5] æ··éŸ³ ===\")\n",
        "voc_audio = AudioSegment.from_file(converted_vocal_path)\n",
        "bgm_audio = AudioSegment.from_file(str(final_inst_path))\n",
        "final_audio = voc_audio.overlay(bgm_audio)\n",
        "ai_cover_path = os.path.join(output_dir, f\"{song_name}_Godtone_Ver.wav\")\n",
        "final_audio.export(ai_cover_path, format=\"wav\")\n",
        "print(f\"   ğŸ’¾ æ··éŸ³å®Œæˆ: {ai_cover_path}\")\n",
        "\n",
        "\n",
        "# --- éšæ®µ 4: Wav2Lip ---\n",
        "print(\"\\n=== [4/5] è¦–è¦ºç”Ÿæˆ (Wav2Lip) ===\")\n",
        "lipsync_video_path = os.path.join(output_dir, f\"{song_name}_lipsync.mp4\")\n",
        "checkpoint_path = \"checkpoints/wav2lip_gan.pth\"\n",
        "\n",
        "if not os.path.exists(lipsync_video_path):\n",
        "    print(\"   â³ æ­£åœ¨ç”Ÿæˆå˜´å‹å½±ç‰‡...\")\n",
        "    cmd = f\"python inference.py --checkpoint_path {checkpoint_path} --face \\\"{image_input_path}\\\" --audio \\\"{ai_cover_path}\\\" --outfile \\\"{lipsync_video_path}\\\" --resize_factor 1\"\n",
        "    subprocess.run(cmd, shell=True, check=True)\n",
        "    print(\"      âœ… å½±ç‰‡ç”Ÿæˆå®Œç•¢\")\n",
        "else:\n",
        "    print(\"   âš ï¸ å½±ç‰‡å·²å­˜åœ¨ï¼Œè·³éã€‚\")\n",
        "\n",
        "\n",
        "# --- éšæ®µ 5: å­—å¹•èˆ‡åˆæˆ ---\n",
        "print(\"\\n=== [5/5] å­—å¹•èˆ‡æœ€çµ‚åˆæˆ ===\")\n",
        "ass_path = os.path.join(output_dir, f\"{song_name}.ass\")\n",
        "final_video_path = os.path.join(output_dir, f\"{song_name}_Final_Ultimate.mp4\")\n",
        "\n",
        "model = stable_whisper.load_model('medium', device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if lyrics_input.strip():\n",
        "    print(f\"   ğŸ¯ å°é½Šæ­Œè©...\")\n",
        "    result = model.align(ai_cover_path, text=lyrics_input.strip(), language=lyrics_language)\n",
        "    try:\n",
        "        final_segments = realign_dual_tracks(result, lyrics_input.strip(), soramimi_input.strip())\n",
        "        generate_ktv_ass_dual(final_segments, ass_path)\n",
        "    except NameError:\n",
        "        print(\"âŒ è­¦å‘Š: æ‰¾ä¸åˆ°å·¥å…·å‡½æ•¸ï¼Œè«‹ç¢ºèª Cell 2 å·²åŸ·è¡Œã€‚\")\n",
        "\n",
        "print(\"   ğŸ¬ æœ€çµ‚æ¸²æŸ“...\")\n",
        "temp_vid, temp_ass = \"temp_src.mp4\", \"temp_sub.ass\"\n",
        "shutil.copy(lipsync_video_path, temp_vid)\n",
        "shutil.copy(ass_path, temp_ass)\n",
        "\n",
        "ffmpeg_cmd = [\n",
        "    \"ffmpeg\", \"-y\", \"-v\", \"error\",\n",
        "    \"-i\", temp_vid, \"-i\", ai_cover_path,\n",
        "    \"-vf\", f\"ass={temp_ass}\",\n",
        "    \"-map\", \"0:v\", \"-map\", \"1:a\",\n",
        "    \"-c:v\", \"libx264\", \"-preset\", \"medium\", \"-crf\", \"18\",\n",
        "    \"-c:a\", \"aac\", \"-b:a\", \"192k\", \"-shortest\",\n",
        "    final_video_path\n",
        "]\n",
        "\n",
        "try:\n",
        "    subprocess.run(ffmpeg_cmd, check=True)\n",
        "    print(f\"\\nğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼æª”æ¡ˆè·¯å¾‘: {final_video_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ åˆæˆå¤±æ•—: {e}\")\n",
        "\n",
        "if os.path.exists(temp_vid): os.remove(temp_vid)\n",
        "if os.path.exists(temp_ass): os.remove(temp_ass)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeAQeDjrEDKG",
        "outputId": "b1394234-8136-4c89-fbad-2aa9ebd62547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Wav2Lip\n",
            "ğŸš€ çµ‚æ¥µæµæ°´ç·šå•Ÿå‹•ï¼ç›®æ¨™æ­Œæ›²ï¼šdemo\n",
            "\n",
            "=== [1/5] éŸ³æºåˆ†é›¢è™•ç† ===\n",
            "   âœ‚ï¸ è™•ç†éŸ³è¨Š: demo.mp3...\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/temp_dual_process/bgm_source/htdemucs\n",
            "Separating track /content/temp_dual_process/demo_clean.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35.099999999999994/35.099999999999994 [00:01<00:00, 18.95seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ‚ï¸ è™•ç†éŸ³è¨Š: demo.mp3...\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/temp_dual_process/vocal_source/htdemucs\n",
            "Separating track /content/temp_dual_process/demo_clean.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35.099999999999994/35.099999999999994 [00:01<00:00, 20.39seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      âœ… éŸ³æºåˆ†é›¢å®Œæˆ\n",
            "\n",
            "=== [2/5] AI è®Šè²è½‰æ› (RVC API - é †åºä¿®æ­£ç‰ˆ) ===\n",
            "Loaded as API: https://r3gm-rvc-zero.hf.space âœ”\n",
            "   ğŸ“¡ ç™¼é€ API è«‹æ±‚...\n",
            "      âœ… è®Šè²æˆåŠŸ: /tmp/gradio/ddbf541dac97902c6f24a85f817f4b8e755b4832e98e8d9f749a4b96d2d3cd3f/vocals_edited_noisereduce.wav\n",
            "\n",
            "=== [3/5] æ··éŸ³ ===\n",
            "   ğŸ’¾ æ··éŸ³å®Œæˆ: /content/drive/MyDrive/RVCè½‰æ›/Final_Ultimate_Output/demo_Godtone_Ver.wav\n",
            "\n",
            "=== [4/5] è¦–è¦ºç”Ÿæˆ (Wav2Lip) ===\n",
            "   â³ æ­£åœ¨ç”Ÿæˆå˜´å‹å½±ç‰‡...\n",
            "      âœ… å½±ç‰‡ç”Ÿæˆå®Œç•¢\n",
            "\n",
            "=== [5/5] å­—å¹•èˆ‡æœ€çµ‚åˆæˆ ===\n",
            "   ğŸ¯ å°é½Šæ­Œè©...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Align: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.86/29.86 [00:00<00:00, 52.96sec/s]\n",
            "Adjustment: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27.76/27.76 [00:00<00:00, 14362.14sec/s]\n",
            "/tmp/ipython-input-3555755754.py:16: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
            "  dt = datetime.datetime.utcfromtimestamp(seconds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ğŸ§© æ­£åœ¨è¨ˆç®—é›™è»Œæ­Œè©å°é½Š...\n",
            "   âœ¨ é›™è»Œ ASS å­—å¹•æª”å·²ç”Ÿæˆ: /content/drive/MyDrive/RVCè½‰æ›/Final_Ultimate_Output/demo.ass\n",
            "   ğŸ¬ æœ€çµ‚æ¸²æŸ“...\n",
            "\n",
            "ğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼æª”æ¡ˆè·¯å¾‘: /content/drive/MyDrive/RVCè½‰æ›/Final_Ultimate_Output/demo_Final_Ultimate.mp4\n"
          ]
        }
      ]
    }
  ]
}